{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exam 2020/06/27 - Exercise #2 - Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data and output folders\n",
    "inputPathPurchases = \"exam_ex2_data/Purchases.txt\"\n",
    "outputPathPart1 = \"outPart1SQL/\"\n",
    "outputPathPart2 = \"outPart2SQL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************\n",
    "# Exercise 2 - Part 1\n",
    "# *****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of Purchases.txt\n",
    "purchasesDF = spark.read.load(inputPathPurchases,\\\n",
    "                            format=\"csv\",\\\n",
    "                            header=False,\\\n",
    "                            inferSchema=True)\\\n",
    ".withColumnRenamed(\"_c0\", \"MID\")\\\n",
    ".withColumnRenamed(\"_c1\", \"CustomerId\")\\\n",
    ".withColumnRenamed(\"_c2\", \"Date\")\\\n",
    ".withColumnRenamed(\"_c3\", \"Price\")\\\n",
    ".cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate purchasesDF to a temporary table\n",
    "purchasesDF.createOrReplaceTempView(\"purchases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the income for each MID in year 2019\n",
    "midsIncomesDF = spark.sql(\"\"\"SELECT MID, SUM(Price) as Income\n",
    "FROM purchases\n",
    "WHERE Date>='2019/01/01' and Date<='2019/12/31'\n",
    "GROUP BY MID\"\"\")\\\n",
    ".cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate midsIncomesDF to a temporary table\n",
    "midsIncomesDF.createOrReplaceTempView(\"MidsIncomesTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the MIDs associated with the highest annual income in 2019\n",
    "selectedMidsDF = spark.sql(\"\"\"SELECT MID\n",
    "FROM MidsIncomesTable, (SELECT MAX(Income) as MaxIncome\n",
    "                        FROM MidsIncomesTable) MaxIncomeTable\n",
    "WHERE Income=MaxIncome\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectedMidsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the result\n",
    "selectedMidsDF.write.csv(outputPathPart1,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************\n",
    "# Exercise 2 - Part 2\n",
    "# *****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a UDF that extract the year part from Date\n",
    "def yearFunc(date):\n",
    "    return int(date.split(\"/\")[0])\n",
    "    \n",
    "spark.udf.register(\"yearFunc\", yearFunc, LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the purchases of the last ten years (i.e., from year 2010 to year 2019) \n",
    "# Compute the number of purchases for each MID in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midYearNumPurchasesDF = spark.sql(\"\"\"SELECT MID, \n",
    "yearFunc(Date) as Year,\n",
    "count(*) as NumPurchases\n",
    "FROM purchases\n",
    "WHERE Date>='2010/01/01' and Date<='2019/12/31'\n",
    "GROUP BY MID, yearFunc(Date)\"\"\")\\\n",
    ".cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate midYearNumPurchasesDF to a temporary table\n",
    "midYearNumPurchasesDF.createOrReplaceTempView(\"MidYearNumPurchs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can provide the hint about the usefulness of the brodcast join\n",
    "midsMaxAnnualPurchasesDF = spark.sql(\"\"\"SELECT\n",
    "/*+ BROADCAST(MaxYearlyPurchases) */ \n",
    "MID, \n",
    "MidYearNumPurchs.Year,\n",
    "NumPurchases\n",
    "FROM MidYearNumPurchs, (SELECT Year, Max(NumPurchases) as MaxNumPurchases\n",
    "                        FROM MidYearNumPurchs\n",
    "                        GROUP BY Year) MaxYearlyPurchases\n",
    "WHERE MidYearNumPurchs.NumPurchases=MaxYearlyPurchases.MaxNumPurchases\n",
    "  AND MidYearNumPurchs.Year=MaxYearlyPurchases.Year\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#midsMaxAnnualPurchasesDF.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count for each MID in how many years it is the most purchased model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate midsMaxAnnualPurchasesRDD to a temporary table\n",
    "midsMaxAnnualPurchasesDF.createOrReplaceTempView(\"midsMaxAnnual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedMIDsDFPartB = spark.sql(\"\"\"SELECT MID\n",
    "FROM midsMaxAnnual\n",
    "GROUP BY MID\n",
    "HAVING COUNT(*)>=2\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectedMIDsDFPartB.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the result\n",
    "selectedMIDsDFPartB.write.csv(outputPathPart2,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
